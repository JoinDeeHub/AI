{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fdca41",
   "metadata": {},
   "source": [
    "# Classification Assignment\n",
    "#### Problem Statement or Requirement:\n",
    "\n",
    "###### A requirement from the Hospital, Management asked us to create a predictive model which will predict the Chronic Kidney Disease (CKD) based on the several parameters. The Client has provided the dataset of the same.\n",
    "\n",
    "###### 1.) Identify your problem statement\n",
    "\n",
    "###### 2.) Tell basic info about the dataset (Total number of rows, columns)\n",
    "\n",
    "###### 3.) Mention the pre-processing method if you’re doing any (like converting string to number – nominal data)\n",
    "\n",
    "###### 4.) Develop a good model with good evaluation metric. You can use any machine learning algorithm; you can create many models. Finally, you have to come up with final model.\n",
    "\n",
    "###### 5.) All the research values of each algorithm should be documented. (You can make tabulation or screenshot of the results.)\n",
    "\n",
    "###### 6.) Mention your final model, justify why u have chosen the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9291b1",
   "metadata": {},
   "source": [
    "1. The hospital wants a reliable predictive model to classify patients into CKD (Chronic Kidney Disease) or Not CKD, using medical attributes.\n",
    "You are tasked with building the best-performing classification model, evaluated using precision, recall, f1-score, and accuracy.\n",
    "\n",
    "Domain: ML\n",
    "\n",
    "Type: Supervised Learning\n",
    "\n",
    "Objective: Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5239d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Libraies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eeff926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Dataset\n",
    "dataset = pd.read_csv('CKD.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57fc4b",
   "metadata": {},
   "source": [
    "2. Tell basic info about the dataset (Total number of rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33415160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows: 399\n",
      "\n",
      "Columns: 25\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp sg   al   su     rbc        pc         pcc  \\\n",
       "0     2.000000  76.459948  c  3.0  0.0  normal  abnormal  notpresent   \n",
       "1     3.000000  76.459948  c  2.0  0.0  normal    normal  notpresent   \n",
       "2     4.000000  76.459948  a  1.0  0.0  normal    normal  notpresent   \n",
       "3     5.000000  76.459948  d  1.0  0.0  normal    normal  notpresent   \n",
       "4     5.000000  50.000000  c  0.0  0.0  normal    normal  notpresent   \n",
       "..         ...        ... ..  ...  ...     ...       ...         ...   \n",
       "394  51.492308  70.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "395  51.492308  70.000000  c  0.0  2.0  normal    normal  notpresent   \n",
       "396  51.492308  70.000000  c  3.0  0.0  normal    normal  notpresent   \n",
       "397  51.492308  90.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "398  51.492308  80.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba         bgr  ...        pcv            wc        rc  htn   dm  \\\n",
       "0    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "1    notpresent  148.112676  ...  34.000000  12300.000000  4.705597   no   no   \n",
       "2    notpresent   99.000000  ...  34.000000   8408.191126  4.705597   no   no   \n",
       "3    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "4    notpresent  148.112676  ...  36.000000  12400.000000  4.705597   no   no   \n",
       "..          ...         ...  ...        ...           ...       ...  ...  ...   \n",
       "394  notpresent  219.000000  ...  37.000000   9800.000000  4.400000   no   no   \n",
       "395  notpresent  220.000000  ...  27.000000   8408.191126  4.705597  yes  yes   \n",
       "396  notpresent  110.000000  ...  26.000000   9200.000000  3.400000  yes  yes   \n",
       "397  notpresent  207.000000  ...  38.868902   8408.191126  4.705597  yes  yes   \n",
       "398  notpresent  100.000000  ...  53.000000   8500.000000  4.900000   no   no   \n",
       "\n",
       "     cad  appet    pe  ane classification  \n",
       "0     no    yes   yes   no            yes  \n",
       "1     no    yes  poor   no            yes  \n",
       "2     no    yes  poor   no            yes  \n",
       "3     no    yes  poor  yes            yes  \n",
       "4     no    yes  poor   no            yes  \n",
       "..   ...    ...   ...  ...            ...  \n",
       "394   no    yes  poor   no            yes  \n",
       "395   no    yes  poor  yes            yes  \n",
       "396   no   poor  poor   no            yes  \n",
       "397   no    yes  poor  yes            yes  \n",
       "398   no    yes  poor   no             no  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             399 non-null    float64\n",
      " 1   bp              399 non-null    float64\n",
      " 2   sg              399 non-null    object \n",
      " 3   al              399 non-null    float64\n",
      " 4   su              399 non-null    float64\n",
      " 5   rbc             399 non-null    object \n",
      " 6   pc              399 non-null    object \n",
      " 7   pcc             399 non-null    object \n",
      " 8   ba              399 non-null    object \n",
      " 9   bgr             399 non-null    float64\n",
      " 10  bu              399 non-null    float64\n",
      " 11  sc              399 non-null    float64\n",
      " 12  sod             399 non-null    float64\n",
      " 13  pot             399 non-null    float64\n",
      " 14  hrmo            399 non-null    float64\n",
      " 15  pcv             399 non-null    float64\n",
      " 16  wc              399 non-null    float64\n",
      " 17  rc              399 non-null    float64\n",
      " 18  htn             399 non-null    object \n",
      " 19  dm              399 non-null    object \n",
      " 20  cad             399 non-null    object \n",
      " 21  appet           399 non-null    object \n",
      " 22  pe              399 non-null    object \n",
      " 23  ane             399 non-null    object \n",
      " 24  classification  399 non-null    object \n",
      "dtypes: float64(13), object(12)\n",
      "memory usage: 78.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\nRows: {dataset.shape[0]}\")\n",
    "print(f\"\\nColumns: {dataset.shape[1]}\\n\\n\")\n",
    "\n",
    "display(dataset)\n",
    "\n",
    "# Displaying the dataset information\n",
    "display(dataset.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bbbcc",
   "metadata": {},
   "source": [
    "3.) Mention the pre-processing method if you’re doing any (like converting string to number – nominal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcf9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical variables to numerical\n",
    "# as the classification column is categorical - ordinal data, will be converted to numerical values using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle categorical and numerical separately\n",
    "categorical_cols = dataset.select_dtypes(include='object').columns\n",
    "numerical_cols = dataset.select_dtypes(exclude='object').columns\n",
    "\n",
    "# Fill missing values\n",
    "dataset[categorical_cols] = dataset[categorical_cols].fillna(dataset[categorical_cols].mode().iloc[0])\n",
    "dataset[numerical_cols] = dataset[numerical_cols].fillna(dataset[numerical_cols].mean())\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    dataset[col] = le.fit_transform(dataset[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46af6dd",
   "metadata": {},
   "source": [
    "4. Develop a good model with good evaluation metric. You can use any machine learning algorithm; you can create many models. Finally, you have to come up with final model.\n",
    "\n",
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2031e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into independent and dependent variables\n",
    "independent = dataset.drop('classification', axis=1)\n",
    "dependent = dataset['classification']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2658ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training set and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent, dependent, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b19f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "StandardScaler = StandardScaler()\n",
    "X_train = StandardScaler.fit_transform(X_train)\n",
    "X_test = StandardScaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e5199a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.962 total time=   1.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=1.000 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.9s[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.981 total time=   1.1s\n",
      "\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.8s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.962 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.981 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.962 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=1.000 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.942 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.981 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.981 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.962 total time=   1.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.981 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=0.942 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=0.962 total time=   2.1s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.962 total time=   2.5s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=0.981 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.981 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=1.000 total time=   1.2s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.981 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.962 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.962 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=1.000 total time=   1.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.962 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.981 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.962 total time=   2.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.981 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.9s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.981 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.962 total time=   0.9s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.962 total time=   2.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.2s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.981 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.962 total time=   2.5s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.981 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.962 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=200;, score=1.000 total time=   1.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=200;, score=0.981 total time=   0.9s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=200;, score=0.962 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=200;, score=0.942 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.981 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.981 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.981 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=200;, score=1.000 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.962 total time=   1.1s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.962 total time=   1.2s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.962 total time=   1.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=300;, score=1.000 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.942 total time=   2.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=auto, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=300;, score=1.000 total time=   1.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.981 total time=   2.2s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.981 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.962 total time=   1.2s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.981 total time=   1.1s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.962 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=0.981 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=200;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.981 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.962 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=1.000 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=0.962 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=2, n_estimators=300;, score=0.962 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.981 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.981 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=1.000 total time=   1.2s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=1.000 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=200;, score=0.962 total time=   0.9s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.962 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.981 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.942 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.981 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.962 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.981 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.0s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=200;, score=0.981 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.962 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.981 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.962 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.0s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=200;, score=0.962 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.962 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=200;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, min_samples_split=10, n_estimators=300;, score=0.981 total time=   1.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.981 total time=   1.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=300;, score=1.000 total time=   0.9s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=100;, score=1.000 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=200;, score=0.962 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=300;, score=0.962 total time=   1.1s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.981 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.981 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=200;, score=0.962 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=200;, score=1.000 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=2, n_estimators=300;, score=1.000 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.2s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.962 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.981 total time=   1.2s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.981 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=300;, score=1.000 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=200;, score=0.962 total time=   1.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=5, n_estimators=300;, score=0.962 total time=   1.0s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.962 total time=   1.0s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=200;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.981 total time=   0.8s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.962 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=100;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=300;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.962 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, min_samples_split=10, n_estimators=300;, score=0.981 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "90 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/deehub/anaconda3/envs/AI/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.98104724 0.98104724 0.98104724\n",
      " 0.97712948 0.97712948 0.98104724 0.97725344 0.98480383 0.98104724\n",
      " 0.98104724 0.98104724 0.98104724 0.98104724 0.97712948 0.98104724\n",
      " 0.98104724 0.98104724 0.97712948        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.98104724 0.98104724 0.98104724 0.98104724 0.98480383 0.98104724\n",
      " 0.97725344 0.97725344 0.97333567 0.98104724 0.98104724 0.98104724\n",
      " 0.98104724 0.98480383 0.98104724 0.98480383 0.98104724 0.97725344]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_split=10, n_estimators=200)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_split=10, n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators':[100, 200, 300],\n",
    "              'max_features':['auto', 'sqrt', 'log2'],\n",
    "              'min_samples_split':[2, 5, 10],\n",
    "              'bootstrap':[True, False]} \n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1,scoring='f1_weighted') \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92005072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "#print(grid.best_params_) \n",
    "result = grid.cv_results_\n",
    "#print(result)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, grid_predictions)\n",
    "\n",
    "# print classification report \n",
    "from sklearn.metrics import classification_report\n",
    "classification_report = classification_report(y_test, grid_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea6968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_macro value for best parameter {'bootstrap': True, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 200}: 0.9924667654735397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,grid_predictions,average='weighted')\n",
    "print(\"The f1_macro value for best parameter {}:\".format(grid.best_params_),f1_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a93c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion Matrix:\n",
      " [[50  1]\n",
      " [ 0 82]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The confusion Matrix:\\n\", confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccec3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The report using RandomForestClassifier :\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        51\n",
      "           1       0.99      1.00      0.99        82\n",
      "\n",
      "    accuracy                           0.99       133\n",
      "   macro avg       0.99      0.99      0.99       133\n",
      "weighted avg       0.99      0.99      0.99       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe report using RandomForestClassifier :\\n\\n\\n\", classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d090b9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test,grid.predict_proba(X_test)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3034d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'auto', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.867569</td>\n",
       "      <td>0.300743</td>\n",
       "      <td>0.052229</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.905846</td>\n",
       "      <td>0.225968</td>\n",
       "      <td>0.058009</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.560602</td>\n",
       "      <td>0.473107</td>\n",
       "      <td>0.092141</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.396934</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>0.030252</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977129</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.045733</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977129</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.170461</td>\n",
       "      <td>0.173553</td>\n",
       "      <td>0.065764</td>\n",
       "      <td>0.026018</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.417484</td>\n",
       "      <td>0.123094</td>\n",
       "      <td>0.034134</td>\n",
       "      <td>0.018459</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.977253</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.044321</td>\n",
       "      <td>0.337024</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.024320</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.460249</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.082343</td>\n",
       "      <td>0.036712</td>\n",
       "      <td>True</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'sqrt', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.687594</td>\n",
       "      <td>0.297005</td>\n",
       "      <td>0.049101</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.185607</td>\n",
       "      <td>0.480375</td>\n",
       "      <td>0.057770</td>\n",
       "      <td>0.025801</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.468054</td>\n",
       "      <td>0.501938</td>\n",
       "      <td>0.080114</td>\n",
       "      <td>0.039949</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.415612</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.905917</td>\n",
       "      <td>0.187741</td>\n",
       "      <td>0.065851</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977129</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.440384</td>\n",
       "      <td>0.311163</td>\n",
       "      <td>0.078344</td>\n",
       "      <td>0.031155</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.367223</td>\n",
       "      <td>0.059690</td>\n",
       "      <td>0.039629</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.958363</td>\n",
       "      <td>0.238478</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.030235</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.468616</td>\n",
       "      <td>0.450513</td>\n",
       "      <td>0.094848</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>True</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 'log2', 'm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977129</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'auto', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.437023</td>\n",
       "      <td>0.098867</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.711514</td>\n",
       "      <td>0.226464</td>\n",
       "      <td>0.059237</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.154951</td>\n",
       "      <td>0.236664</td>\n",
       "      <td>0.091840</td>\n",
       "      <td>0.058540</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.343976</td>\n",
       "      <td>0.110459</td>\n",
       "      <td>0.029023</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.880552</td>\n",
       "      <td>0.286131</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.048823</td>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.311940</td>\n",
       "      <td>0.089849</td>\n",
       "      <td>0.026964</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.977253</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.531082</td>\n",
       "      <td>0.041962</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.977253</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.051064</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.080517</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>False</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'sqrt', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.973336</td>\n",
       "      <td>0.019629</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.455719</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.514305</td>\n",
       "      <td>0.030971</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.073077</td>\n",
       "      <td>0.205122</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.441032</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.479983</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.307006</td>\n",
       "      <td>0.291423</td>\n",
       "      <td>0.079558</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.292501</td>\n",
       "      <td>0.075888</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.803027</td>\n",
       "      <td>0.185170</td>\n",
       "      <td>0.049443</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.610651</td>\n",
       "      <td>0.194524</td>\n",
       "      <td>0.036380</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>False</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 'log2', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961755</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.977253</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002019      0.000337         0.000000        0.000000   \n",
       "1        0.002393      0.001107         0.000000        0.000000   \n",
       "2        0.001476      0.000139         0.000000        0.000000   \n",
       "3        0.002434      0.000860         0.000000        0.000000   \n",
       "4        0.003000      0.003294         0.000000        0.000000   \n",
       "5        0.002167      0.001672         0.000000        0.000000   \n",
       "6        0.002392      0.001710         0.000000        0.000000   \n",
       "7        0.003277      0.001774         0.000000        0.000000   \n",
       "8        0.004441      0.001921         0.000000        0.000000   \n",
       "9        0.867569      0.300743         0.052229        0.031300   \n",
       "10       0.905846      0.225968         0.058009        0.023008   \n",
       "11       1.560602      0.473107         0.092141        0.038295   \n",
       "12       0.396934      0.051404         0.030252        0.012647   \n",
       "13       1.045733      0.506712         0.045849        0.015159   \n",
       "14       1.170461      0.173553         0.065764        0.026018   \n",
       "15       0.417484      0.123094         0.034134        0.018459   \n",
       "16       1.044321      0.337024         0.057367        0.024320   \n",
       "17       1.460249      0.402344         0.082343        0.036712   \n",
       "18       0.687594      0.297005         0.049101        0.023800   \n",
       "19       1.185607      0.480375         0.057770        0.025801   \n",
       "20       1.468054      0.501938         0.080114        0.039949   \n",
       "21       0.415612      0.069395         0.026723        0.008360   \n",
       "22       0.905917      0.187741         0.065851        0.029806   \n",
       "23       1.440384      0.311163         0.078344        0.031155   \n",
       "24       0.367223      0.059690         0.039629        0.029133   \n",
       "25       0.958363      0.238478         0.061881        0.030235   \n",
       "26       1.468616      0.450513         0.094848        0.047784   \n",
       "27       0.002139      0.001789         0.000000        0.000000   \n",
       "28       0.002518      0.001596         0.000000        0.000000   \n",
       "29       0.001758      0.000954         0.000000        0.000000   \n",
       "30       0.001587      0.000657         0.000000        0.000000   \n",
       "31       0.002591      0.002805         0.000000        0.000000   \n",
       "32       0.002365      0.001474         0.000000        0.000000   \n",
       "33       0.004989      0.004199         0.000000        0.000000   \n",
       "34       0.002776      0.001555         0.000000        0.000000   \n",
       "35       0.003078      0.002016         0.000000        0.000000   \n",
       "36       0.437023      0.098867         0.022254        0.003010   \n",
       "37       0.711514      0.226464         0.059237        0.026102   \n",
       "38       1.154951      0.236664         0.091840        0.058540   \n",
       "39       0.343976      0.110459         0.029023        0.010178   \n",
       "40       0.880552      0.286131         0.068038        0.032964   \n",
       "41       1.048823      0.197590         0.076900        0.022736   \n",
       "42       0.311940      0.089849         0.026964        0.013193   \n",
       "43       0.531082      0.041962         0.035927        0.004666   \n",
       "44       1.051064      0.190650         0.080517        0.028981   \n",
       "45       0.455719      0.084714         0.034210        0.008013   \n",
       "46       0.514305      0.030971         0.035877        0.001203   \n",
       "47       1.073077      0.205122         0.072199        0.018822   \n",
       "48       0.441032      0.197144         0.027400        0.009013   \n",
       "49       0.479983      0.003070         0.034226        0.000888   \n",
       "50       1.307006      0.291423         0.079558        0.034884   \n",
       "51       0.292501      0.075888         0.022530        0.006340   \n",
       "52       0.803027      0.185170         0.049443        0.018213   \n",
       "53       0.610651      0.194524         0.036380        0.012692   \n",
       "\n",
       "    param_bootstrap param_max_features  param_min_samples_split  \\\n",
       "0              True               auto                        2   \n",
       "1              True               auto                        2   \n",
       "2              True               auto                        2   \n",
       "3              True               auto                        5   \n",
       "4              True               auto                        5   \n",
       "5              True               auto                        5   \n",
       "6              True               auto                       10   \n",
       "7              True               auto                       10   \n",
       "8              True               auto                       10   \n",
       "9              True               sqrt                        2   \n",
       "10             True               sqrt                        2   \n",
       "11             True               sqrt                        2   \n",
       "12             True               sqrt                        5   \n",
       "13             True               sqrt                        5   \n",
       "14             True               sqrt                        5   \n",
       "15             True               sqrt                       10   \n",
       "16             True               sqrt                       10   \n",
       "17             True               sqrt                       10   \n",
       "18             True               log2                        2   \n",
       "19             True               log2                        2   \n",
       "20             True               log2                        2   \n",
       "21             True               log2                        5   \n",
       "22             True               log2                        5   \n",
       "23             True               log2                        5   \n",
       "24             True               log2                       10   \n",
       "25             True               log2                       10   \n",
       "26             True               log2                       10   \n",
       "27            False               auto                        2   \n",
       "28            False               auto                        2   \n",
       "29            False               auto                        2   \n",
       "30            False               auto                        5   \n",
       "31            False               auto                        5   \n",
       "32            False               auto                        5   \n",
       "33            False               auto                       10   \n",
       "34            False               auto                       10   \n",
       "35            False               auto                       10   \n",
       "36            False               sqrt                        2   \n",
       "37            False               sqrt                        2   \n",
       "38            False               sqrt                        2   \n",
       "39            False               sqrt                        5   \n",
       "40            False               sqrt                        5   \n",
       "41            False               sqrt                        5   \n",
       "42            False               sqrt                       10   \n",
       "43            False               sqrt                       10   \n",
       "44            False               sqrt                       10   \n",
       "45            False               log2                        2   \n",
       "46            False               log2                        2   \n",
       "47            False               log2                        2   \n",
       "48            False               log2                        5   \n",
       "49            False               log2                        5   \n",
       "50            False               log2                        5   \n",
       "51            False               log2                       10   \n",
       "52            False               log2                       10   \n",
       "53            False               log2                       10   \n",
       "\n",
       "    param_n_estimators                                             params  \\\n",
       "0                  100  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "1                  200  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "2                  300  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "3                  100  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "4                  200  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "5                  300  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "6                  100  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "7                  200  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "8                  300  {'bootstrap': True, 'max_features': 'auto', 'm...   \n",
       "9                  100  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "10                 200  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "11                 300  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "12                 100  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "13                 200  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "14                 300  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "15                 100  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "16                 200  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "17                 300  {'bootstrap': True, 'max_features': 'sqrt', 'm...   \n",
       "18                 100  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "19                 200  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "20                 300  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "21                 100  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "22                 200  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "23                 300  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "24                 100  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "25                 200  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "26                 300  {'bootstrap': True, 'max_features': 'log2', 'm...   \n",
       "27                 100  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "28                 200  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "29                 300  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "30                 100  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "31                 200  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "32                 300  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "33                 100  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "34                 200  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "35                 300  {'bootstrap': False, 'max_features': 'auto', '...   \n",
       "36                 100  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "37                 200  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "38                 300  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "39                 100  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "40                 200  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "41                 300  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "42                 100  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "43                 200  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "44                 300  {'bootstrap': False, 'max_features': 'sqrt', '...   \n",
       "45                 100  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "46                 200  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "47                 300  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "48                 100  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "49                 200  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "50                 300  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "51                 100  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "52                 200  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "53                 300  {'bootstrap': False, 'max_features': 'log2', '...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1                 NaN                NaN                NaN   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "5                 NaN                NaN                NaN   \n",
       "6                 NaN                NaN                NaN   \n",
       "7                 NaN                NaN                NaN   \n",
       "8                 NaN                NaN                NaN   \n",
       "9                 1.0           0.961755           0.981217   \n",
       "10                1.0           0.961755           0.981217   \n",
       "11                1.0           0.961755           0.981217   \n",
       "12                1.0           0.942166           0.981217   \n",
       "13                1.0           0.942166           0.981217   \n",
       "14                1.0           0.961755           0.981217   \n",
       "15                1.0           0.961755           0.981217   \n",
       "16                1.0           0.961755           1.000000   \n",
       "17                1.0           0.961755           0.981217   \n",
       "18                1.0           0.961755           0.981217   \n",
       "19                1.0           0.961755           0.981217   \n",
       "20                1.0           0.961755           0.981217   \n",
       "21                1.0           0.961755           0.981217   \n",
       "22                1.0           0.942166           0.981217   \n",
       "23                1.0           0.961755           0.981217   \n",
       "24                1.0           0.961755           0.981217   \n",
       "25                1.0           0.961755           0.981217   \n",
       "26                1.0           0.942166           0.981217   \n",
       "27                NaN                NaN                NaN   \n",
       "28                NaN                NaN                NaN   \n",
       "29                NaN                NaN                NaN   \n",
       "30                NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33                NaN                NaN                NaN   \n",
       "34                NaN                NaN                NaN   \n",
       "35                NaN                NaN                NaN   \n",
       "36                1.0           0.961755           0.981217   \n",
       "37                1.0           0.961755           0.981217   \n",
       "38                1.0           0.961755           0.981217   \n",
       "39                1.0           0.961755           0.981217   \n",
       "40                1.0           0.961755           1.000000   \n",
       "41                1.0           0.961755           0.981217   \n",
       "42                1.0           0.961755           0.981217   \n",
       "43                1.0           0.961755           0.981217   \n",
       "44                1.0           0.942166           0.981217   \n",
       "45                1.0           0.961755           0.981217   \n",
       "46                1.0           0.961755           0.981217   \n",
       "47                1.0           0.961755           0.981217   \n",
       "48                1.0           0.961755           0.981217   \n",
       "49                1.0           0.961755           1.000000   \n",
       "50                1.0           0.961755           0.981217   \n",
       "51                1.0           0.961755           1.000000   \n",
       "52                1.0           0.961755           0.981217   \n",
       "53                1.0           0.961755           0.981217   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0                 NaN                NaN              NaN             NaN   \n",
       "1                 NaN                NaN              NaN             NaN   \n",
       "2                 NaN                NaN              NaN             NaN   \n",
       "3                 NaN                NaN              NaN             NaN   \n",
       "4                 NaN                NaN              NaN             NaN   \n",
       "5                 NaN                NaN              NaN             NaN   \n",
       "6                 NaN                NaN              NaN             NaN   \n",
       "7                 NaN                NaN              NaN             NaN   \n",
       "8                 NaN                NaN              NaN             NaN   \n",
       "9            0.962264           1.000000         0.981047        0.016991   \n",
       "10           0.962264           1.000000         0.981047        0.016991   \n",
       "11           0.962264           1.000000         0.981047        0.016991   \n",
       "12           0.962264           1.000000         0.977129        0.022389   \n",
       "13           0.962264           1.000000         0.977129        0.022389   \n",
       "14           0.962264           1.000000         0.981047        0.016991   \n",
       "15           0.962264           0.981031         0.977253        0.014229   \n",
       "16           0.962264           1.000000         0.984804        0.018612   \n",
       "17           0.962264           1.000000         0.981047        0.016991   \n",
       "18           0.962264           1.000000         0.981047        0.016991   \n",
       "19           0.962264           1.000000         0.981047        0.016991   \n",
       "20           0.962264           1.000000         0.981047        0.016991   \n",
       "21           0.962264           1.000000         0.981047        0.016991   \n",
       "22           0.962264           1.000000         0.977129        0.022389   \n",
       "23           0.962264           1.000000         0.981047        0.016991   \n",
       "24           0.962264           1.000000         0.981047        0.016991   \n",
       "25           0.962264           1.000000         0.981047        0.016991   \n",
       "26           0.962264           1.000000         0.977129        0.022389   \n",
       "27                NaN                NaN              NaN             NaN   \n",
       "28                NaN                NaN              NaN             NaN   \n",
       "29                NaN                NaN              NaN             NaN   \n",
       "30                NaN                NaN              NaN             NaN   \n",
       "31                NaN                NaN              NaN             NaN   \n",
       "32                NaN                NaN              NaN             NaN   \n",
       "33                NaN                NaN              NaN             NaN   \n",
       "34                NaN                NaN              NaN             NaN   \n",
       "35                NaN                NaN              NaN             NaN   \n",
       "36           0.962264           1.000000         0.981047        0.016991   \n",
       "37           0.962264           1.000000         0.981047        0.016991   \n",
       "38           0.962264           1.000000         0.981047        0.016991   \n",
       "39           0.962264           1.000000         0.981047        0.016991   \n",
       "40           0.962264           1.000000         0.984804        0.018612   \n",
       "41           0.962264           1.000000         0.981047        0.016991   \n",
       "42           0.962264           0.981031         0.977253        0.014229   \n",
       "43           0.962264           0.981031         0.977253        0.014229   \n",
       "44           0.962264           0.981031         0.973336        0.019629   \n",
       "45           0.962264           1.000000         0.981047        0.016991   \n",
       "46           0.962264           1.000000         0.981047        0.016991   \n",
       "47           0.962264           1.000000         0.981047        0.016991   \n",
       "48           0.962264           1.000000         0.981047        0.016991   \n",
       "49           0.962264           1.000000         0.984804        0.018612   \n",
       "50           0.962264           1.000000         0.981047        0.016991   \n",
       "51           0.962264           1.000000         0.984804        0.018612   \n",
       "52           0.962264           1.000000         0.981047        0.016991   \n",
       "53           0.962264           0.981031         0.977253        0.014229   \n",
       "\n",
       "    rank_test_score  \n",
       "0                37  \n",
       "1                37  \n",
       "2                37  \n",
       "3                37  \n",
       "4                37  \n",
       "5                37  \n",
       "6                37  \n",
       "7                37  \n",
       "8                37  \n",
       "9                 5  \n",
       "10                5  \n",
       "11                5  \n",
       "12               32  \n",
       "13               32  \n",
       "14                5  \n",
       "15               28  \n",
       "16                1  \n",
       "17                5  \n",
       "18                5  \n",
       "19                5  \n",
       "20                5  \n",
       "21                5  \n",
       "22               32  \n",
       "23                5  \n",
       "24                5  \n",
       "25                5  \n",
       "26               32  \n",
       "27               37  \n",
       "28               37  \n",
       "29               37  \n",
       "30               37  \n",
       "31               37  \n",
       "32               37  \n",
       "33               37  \n",
       "34               37  \n",
       "35               37  \n",
       "36                5  \n",
       "37                5  \n",
       "38                5  \n",
       "39                5  \n",
       "40                1  \n",
       "41                5  \n",
       "42               28  \n",
       "43               28  \n",
       "44               36  \n",
       "45                5  \n",
       "46                5  \n",
       "47                5  \n",
       "48                5  \n",
       "49                1  \n",
       "50                5  \n",
       "51                1  \n",
       "52                5  \n",
       "53               28  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(result)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf4c64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to random_forest_classification_model.sav and loaded successfully, but predictions do NOT match!\n",
      "\n",
      "Number of mismatches: 1\n",
      "Indices of mismatches: [36]\n",
      "Best parameters found: {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Best score achieved: 0.9886555957105589\n",
      "\n",
      "Feature importances: [5.45378824e-03 1.14580006e-02 1.09374801e-01 5.55380511e-02\n",
      " 7.18205046e-03 3.04305786e-03 5.36216606e-03 1.65807743e-04\n",
      " 0.00000000e+00 3.95443188e-02 2.49318515e-02 1.54922492e-01\n",
      " 1.95550676e-02 3.44568438e-03 2.05607660e-01 1.21294160e-01\n",
      " 6.01661654e-03 1.03205150e-01 4.77069326e-02 6.25884267e-02\n",
      " 0.00000000e+00 3.75556359e-03 4.48133276e-03 5.36702109e-03]\n",
      "\n",
      "Feature names: ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "\n",
      "Feature importances sorted by importance:\n",
      "    Feature  Importance\n",
      "14    hrmo    0.205608\n",
      "11      sc    0.154922\n",
      "15     pcv    0.121294\n",
      "2       sg    0.109375\n",
      "17      rc    0.103205\n",
      "19      dm    0.062588\n",
      "3       al    0.055538\n",
      "18     htn    0.047707\n",
      "9      bgr    0.039544\n",
      "10      bu    0.024932\n",
      "12     sod    0.019555\n",
      "1       bp    0.011458\n",
      "4       su    0.007182\n",
      "16      wc    0.006017\n",
      "0      age    0.005454\n",
      "23     ane    0.005367\n",
      "6       pc    0.005362\n",
      "22      pe    0.004481\n",
      "21   appet    0.003756\n",
      "13     pot    0.003446\n",
      "5      rbc    0.003043\n",
      "7      pcc    0.000166\n",
      "8       ba    0.000000\n",
      "20     cad    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the model to a file\n",
    "good_fit_model_filename = \"random_forest_classification_model.sav\"\n",
    "pickle.dump(grid, open(good_fit_model_filename, 'wb'))\n",
    "# Load the model from a file\n",
    "loaded_model = pickle.load(open(good_fit_model_filename, 'rb'))\n",
    "# Make predictions using the loaded model\n",
    "loaded_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Check if the loaded predictions match the original predictions\n",
    "if np.array_equal(grid_predictions, loaded_predictions):\n",
    "\tprint(f\"\\nModel saved to {good_fit_model_filename} and loaded successfully. Predictions match.\\n\")\n",
    "else:\n",
    "\tprint(f\"\\nModel saved to {good_fit_model_filename} and loaded successfully, but predictions do NOT match!\\n\")\n",
    "\t# Optionally, print mismatches for debugging\n",
    "\tmismatches = np.where(grid_predictions != loaded_predictions)[0]\n",
    "\tprint(f\"Number of mismatches: {len(mismatches)}\")\n",
    "\tprint(f\"Indices of mismatches: {mismatches}\")\n",
    " \n",
    "# Display the best parameters found by GridSearchCV\n",
    "print(f\"Best parameters found: {grid.best_params_}\\n\")\n",
    "\n",
    "# Display the best score achieved by GridSearchCV\n",
    "print(f\"Best score achieved: {grid.best_score_}\\n\")\n",
    "\n",
    "# Display the feature importances\n",
    "importances = grid.best_estimator_.feature_importances_\n",
    "print(f\"Feature importances: {importances}\\n\")\n",
    "# Display the feature names\n",
    "feature_names = independent.columns\n",
    "print(f\"Feature names: {feature_names.tolist()}\\n\")\n",
    "# Display the feature importances in a DataFrame\n",
    "feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "# Display the sorted feature importances\n",
    "print(\"Feature importances sorted by importance:\\n\", feature_importances_df)\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances_df['Feature'], feature_importances_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importances from Random Forest Classifier')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()          \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
